Once understood these, you understand word embeddings:

"Depending on the corpus of text we select to train a word embedding model, different word embeddings will be created according to the context of the words in the given corpus. The larger and more generic a corpus, however, the more generalizable the word embeddings become." - Codecademy wordembeddings lesson 7/8



sources and ressources:

 - gensim package to  train your own word2vec model (https://radimrehurek.com/gensim/)